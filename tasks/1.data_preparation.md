# Data preparation for Training

We will follow one of the formats below to prepare our data for training Small Language Models (SLMs).

## Format 1: IBM Granite:
- Follow the [IBM Granite format on Colab](https://colab.research.google.com/drive/1k4MS3KPwzVFBHzq9DnomZahtsSrswOED?usp=sharing) or see Jupyter notebook `IBM_format.ipynb` in this repository.


## Format 2: Gemma3 models:
- Follow the [Gemma3 format on Colab](https://colab.research.google.com/drive/1iKjikGWTg3WRJ1Y4LAOqBGAsm75utqWy?usp=sharing) or see Jupyter notebook `gemma3_format.ipynb` in this repository.

## Format 3: GPT-OSS models:
- Follow the [GPT-OSS format on Colab](https://colab.research.google.com/drive/1D_j_oyharxMnCN7MEO6jaKmPCI-l5CGG?usp=sharing) or see Jupyter notebook `gptoss_format.ipynb` in this repository.

Return [README.md](../README.md)